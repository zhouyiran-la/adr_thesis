
### 2.1 基础理论

### 2.1.1 GoogLeNet简介

GoogLeNet\[ref]是谷歌公司于2014年推出的全新深度神经网络结构，并于同年ImageNet图像分类任务中击败VGGNet取得冠军。在此之前大多数经典DNNs结构（如AlexNet，VGGNet）都是通过不断堆叠网络深度来提升模型学习效果，但一味增加网络深度会带来过拟合、参数爆炸、梯度消失等问题。据此GoogLeNet在网络结构设计时创新性地运用模块化思想，引入Inception模块（Inception module），在增加网络模型深度与广度的同时显著减小了网络参数数量，Inception模块结构如图2-1所示。
\[图2-1]
可以看到Inception模块共有4个分支，3不同大小卷积核（1x1，3x3，5x5）和1个最大池化单元。Inception模块将不同大小卷积核在各分支中排列组合，使网络能够学习到不同尺度的特征，从而增强其对于图像信息的表征能力。在上述三种卷积核中，使用1x1卷积核进行的卷积操作称为逐点卷积（Pointwise Convolution，PW），其作用主要体现在两方面：一方面，最大池化单元无法降低特征图通道数，若在此分支上不做任何处理，Inception模块的特征图输出深度必然会大于输入深度，如此网络深度与计算量将会不断累积，引入1x1卷积核能够对特征图进行压缩降维，减少网络参数数量。另一方面，受Network in Network（NiN）\[ref]启发，连续卷积操作（如先进行1x1卷积，再进行3x3卷积）能够提升模型非线性拟合能力，逐点卷积与一般卷积操作流程对比见图2-2。需要注意的是，本文并未采用GoogLeNet完整网络结构\[ref]，而是对其作出了删减与改进以更加适配无人机设备，此外，Inception模块如今经过了多次发展迭代（Inception v1，Inception v2，Inception v3，Xception），本文后续在自主无人机竞速算法设计中采用Inception v1结构。
\[图2-2]

#### 2.1.2 分组（逐点）卷积与通道重组方法介绍

由前述内容可知，逐点卷积对降低GoogLeNet计算开销具有关键作用，但由图2-2易知逐点卷积与常规卷积操作皆为全通道卷积，即特征图通道数等于卷积核通道数，而在轻量化网络结构中逐点卷积运算量在网络总运算量中占比很大，反而成为影响网络性能的一大因素。受\[ref]中工作启发，利用分组逐点卷积实现通道稀疏连接能够进一步降低网络模型计算量与参数数量，即先将输入特征图按通道（Channels）分为若干组，之后每组再进行逐点卷积操作，图2-3展示了其核心思路。
\[图2-3]
公式说明略。

然而，分组卷积（分组逐点卷积）中每组输出仅和其组内输入相关，即组与组之间无法进行特征通信，以图2-3为例，组1中2个特征图输出（红色部分）实际只利用了组1中4个输入特征图信息，而与其他两组信息无关，这会一定程度上导致网络特征提取能力降低，进一步导致模型精度下降。针对这一弊端，可以在分组卷积结束后对所有输出特征图进行排列组合以实现组间特征交换，这一过程被称为通道重组（Channel Shuffle），通道重组保证了之后的卷积层输入能够利用全组特征信息。具体重组策略为：依据先前假设，分组卷积后输出特征图通道数C=g\*n，输出特征图维度为，首先将C所在维度重构为（g，n），转置之后再重新平铺为g\*n个通道，图2-4为通道重组过程示意图（基于图2-3）。
\[图2-4]



### 2.2 整体算法框架设计

#### 2.2.1 算法流程设计

由1.2可知，传统自主无人机竞速策略分为感知、规划、控制三个阶段，每阶段有其特定的目标任务与服务范围，若一一针对每个环节设计具体方案无疑会降低任务可实施性，而借助神经网络端到端特性可以在保证精度前提下充分降低设计与实现难度。依据这一思路，参考\[ref]\[ref]\[ref]中工作，本节主要介绍在GoogLeNet框架下设计深度神经网络结构以代替传统竞速策略中的三个环节，并基于上述分组逐点卷积策略作出进一步改进，最终实现无人机单目图像输入（第一人称主视角）到控制指令的直接映射，算法整体流程如图2-5所示。无人机所采集的多张连续图像帧首先会排列整合成一张拼贴图像（后续称之为Mosaic，生成方法详见2.2.2）作为实际网络输入，最终网络将预测输出四个指令，其中为角度指令，分别表示无人机机架的滚转角和俯仰角， 为速度指令，分别表示无人机偏航角转速和垂直方向速度（也可近似理解为高度）。

#### 2.2.2 输入图像处理

上一小节提到在本文所提出的算法框架中网络输入并非常规单一图像，而是由多张连续图像帧拼贴而成的Mosaic，采用这一设计的主要原因有两个方面：一方面，受启发于视频分类任务，此类任务中利用图像帧间的时序信息是其研究领域中重要一环，而视频序列中相邻图像帧之间往往存在大量信息冗余，故通常会事先对视频序列进行采样，再将样本数据一次或多次送入网络。同理，无人机设备所采集到的连续图像帧也一定程度上包含了某些时间维度信息（如无人机相对于障碍门的运动趋势），此类信息若能成功被网络学习将有助于提升网络模型精度以预测出更为有效的控制指令；另一方面，若将多张图像帧打包共同作为网络输入，在后续进行特征融合时容易导致通道数冗余，网络参数过多等问题，这并不符合无人机设备对于轻量化神经网络结构的要求，Mosaic能够在单一图像输入条件下同时为网络提供空间维度（图像本身表层特征）与时间维度信息（运动变化特征）。
\[图2-5 Mosaic示例]
Mosaic生成方法中需重点解决两个问题：（1）确定组成Mosaic的图像帧数量 ；（2）Mosaic更新策略。问题（1）是一个自定义问题，理论上可以以任意数量图像帧生成Mosaic，图像帧数量越多，可以为网络提供更多特征信息，但同时时间成本也更大。确定图像帧数量的一种可行方案是事先定义好若干备选选项，如4、6、8个图像帧，之后分别据此构建训练集与测试集，比较模型在不同数据集上的表现以选定最佳方案。问题（2）中Mosaic更新策略主要用于模型验证阶段，该阶段需要根据无人机机载摄像头采集到的视频流实时生成Mosaic，更新Mosaic时应按照一定采样频率（如每隔5帧对当前视频流采样一次）。此外，由于无人机自主避障时飞行速度具有波动性，速度变化量达到一定阈值时更新频率也应做出相应调整，例如无人机在起飞阶段速度通常比较缓慢，此时可以采用逐帧采样方法，若Mosaic位置已满，应根据先进先出原则移除当前Mosaic中第一个图像元素，注意完整Mosaic生成后图像大小往往不符合网络输入统一标准，送入网络推理前应先经过缩放处理，Mosaic更新流程详见图2-5。
\[图2-5]

#### 2.2.3 网络结构设计

在网络结构设计中，相比于单分支网络，多分支网络结构中每个分支可以只预测输出某一项明确指令，这往往有助于提升模型精度，且对于输入数据变化具有较强鲁棒性。据2.2.1中所述，本文网络输出为四个控制指令 ，由于 皆为无人机角度姿态， 和 为速度指令，故计划将 作为同组输出， 和 分别作为单组输出。图2-6展示了本文网络结构整体框架，该网络共有三个并行分支，每个分支具有相同结构不同网络权重，第一分支（从上至下）预测无人机滚转角与俯仰角，第二分支预测偏航角速度，第三分支预测垂直速度。单个分支网络结构参照GoogLeNet框架设计，每分支共有4个卷积层，3个Inception模块（具体介绍详见2.1.1），4个最大池化层，1个全连接层，2个批标准化层，为进一步轻量化网络结构以适应无人机设备，本次工作并未采用完整GoogLeNet框架，而是对其做出了如下改进：
（1）舍弃辅助分类器结构。GoogLeNet在网络不同层次中插入了两个辅助分类器，主要由两个连续全连接层和一个Softmax分类器组成，在模型训练阶段辅助分类器能够在网络中间层提供额外分类预测，进一步增强网络梯度流，同时辅助分类器误差也会依权重加入到主损失函数中（相当于加入正则因子）防止网络模型过拟合，但本文中网络只需预测输出4个控制指令，并非强分类任务，辅助分类器虽能带来模型精度上的提升，但也引入了大量网络参数，增加了额外计算开销。
（2）Inception模块个数减至3个。与（2）类似，减少Inception模块个数也是为了进一步简化网络结构，GoogLeNet原始结构中共采用了9个Inception模块，网络深度达到27层（包括池化层），考虑到无人机等边缘设备受计算资源与功耗限制以及后续模型部署难度，在网络结构设计时应尽量减小模型复杂度。
（3）使用分组卷积（分组逐点卷积）与通道重组策略。如图2-6所示，本文网络结构除第一个卷积层外，其余三个卷积层皆使用分组卷积策略（第二与第四卷积层为逐点分组卷积），为避免组间特征信息隔离，本文设计在第二与第三两个连续卷积层之间进行通道重组，即在第二层分组卷积操作后重新组合各分组输出特征图（重组策略详见2.1.2）。分组卷积策略能够进一步减少模型参数量与计算力（详细推导见2.1.2），而通道重组则能够保证组间信息交互以减少特征损失。
网络损失函数采用平方损失函数，如式2-3中所示， 表示某一控制指令预测值， 表示对应真值，要完成所有至指令预测，需计算4次损失函数。

### 2.3 自主无人机竞速仿真环境搭建及模拟飞行数据采集

#### 2.3.1 ROS-Gazebo仿真平台介绍

ROS（Robot Operating System）是一个应用于机器人开发的开源元操作系统\[ref]，起源于斯坦福大学于2007年设立的STAIR研发项目，此后ROS不断发展壮大，2014年OSRF发布了第一个ROS长期支持版ROS Indigo，为更好地服务于机器人开发领域，OSRF每两年发布一个ROS长期支持版并与Ubuntu Linux发行版生命周期（5年）同步，目前ROS最新长期支持版本为ROS Noetic。ROS核心功能主要分为通信机制、开发工具、应用功能、生态系统四个方面，ROS在松耦合分布式通讯框架下通过发布话题消息来连接各个进程节点，并具备物理仿真平台（Gazebo）、三维可视化工具（Rviz）、命令行编译工具（Catkin）等基础开发组件，能够实现机器人导航、建图、控制规划等多种应用功能。此外，ROS庞大且丰富的生态也是其重要特点之一：个人和企业能够在Github等开源代码仓库共享软件包；ROS wiki提供了完备优质的ROS教程与开发文档；全世界机器人开发人员可以在ROS Awnsers中查询并提问相关技术难点。

Gazebo是一款开源机器人物理仿真平台，用于开发和测试机器人软件。Gazebo通过自带物理引擎模拟重力、摩擦力、碰撞、惯性等基本物理现象，具体来说，物理引擎根据机器人自身模型和物理参数，能够计算出机器人在各个状态下的运动学和动力学特征，从而模拟机器人和真实环境间的交互过程。同时，它可以集成到ROS中，使开发人员可以在ROS中快速构建和测试机器人控制，感知和路径规划等算法，Gazebo界面示意图如图2-7所示。总得来说，Gazebo具有以下特点：
（1）支持多种机器人：Gazebo支持多种机器人模型，包括四轮驱动车辆、无人机、人形机器人等。用户可以自由地添加和修改机器人模型以满足特定仿真需求。   
（2）支持多种传感器：Gazebo支持多种传感器模型，如激光雷达、RGB-D相机、摄像头、IMU等。这些传感器可以用于获取机器人周围的环境信息，从而实现定位、建图和导航等任务。
（3）自定义模拟场景：Gazebo允许用户自定义模拟场景，包括障碍物、建筑物、贴图等。一方面，Gazebo官方提供了大量基础场景元素（SDF文件），用户在Gazebo中只需通过简单拖动便可搭建出基础仿真场景（世界文件），另一方面，用户可以根据自身需求将其他外部场景元素模型导入Gazebo，或者直接修改原有世界文件来创建更加复杂的仿真场景。
（4）良好的性能和可扩展性：Gazebo使用高性能物理引擎和OpenGL渲染引擎，能够处理大量机器人、传感器和环境元素。此外，Gazebo还支持插件机制，用户可以通过编.写插件来扩展系统功能。
Gazebo和ROS两者紧密相关，Gazebo是ROS中最主流的物理仿真器，由于ROS完整版本默认安装Gazebo，因此Gazebo通常被视为ROS的一部分。开发人员可以使用ROS在Gazebo仿真环境中对机器人实施控制，如利用roslaunch命令可以方便地启动带有机器人的仿真场景；ROS某些元功能包（gazebo_ros_pkgs）能够保证ROS进程节点与Gazebo仿真实体进行通信。总之，Gazebo为ROS开发机器人应用程序提供重要技术部件，ROS提供了与Gazebo交互的工具和服务，使得开发人员可以更轻松地使用Gazebo进行仿真实验。在自主无人机竞速研究中，Gazebo与ROS相结合可以帮助开发人员有效测试和优化自主无人机控制算法，加速研究进展。
\[图2-7]



#### 2.3.2 仿真环境搭建及数据采集过程设计

模型数据集通常有两种来源，一种是在真实场景中采集，另一种则是搭建仿真环境获取，本文基于第二种方法，以ROS-Gazebo仿真平台为例介绍数据采集过程。ROS-Gazebo仿真环境搭建流程如下：
（1）无人机建模。如今许多企业、组织和无人机自动驾驶平台开源无人机模型，如RotorS、PX4、Parrot AR.Drone及Parrot bebop2等。
（2）搭建仿真赛道场景，主要包括赛道地形、飞行障碍物等。
（3）编写launch文件，将无人机模型与赛道场景集成至Gazebo。
（4）利用ROS编程工具包（rospy）实现Gazebo中无人机模型和控制程序（自主无人机竞速算法）桥接。

图2-8展示了ROS-Gazebo仿真环境搭建结果，共有2个竞速赛道场景（椭圆型赛道与8字形赛道），赛道中障碍门高度与朝向皆为任意值，无人机模型采用Parrot bebop2，可以实现仿真环境手动控制飞机。

为简化数据集构建过程，无人机在穿越障碍门时的动作响应可以大致分为4类（七个基本动作），分别为直行，左右平移，上下运动，顺时针逆时针旋转，整个数据集构建围绕上述七个基本动作。具体来说，不同动作响应对应障碍门位于无人机视野的不同位置，同样也对应不同控制指令。以向右运动为例，此时无人机实际位于障碍门左侧，障碍门位于无人机视野右侧，人手动操控无人机运动，一旦指令发出，该指令（）与其对应视野图像将被同时记录，其中图像作为样本数据，指令作为标签数据，其余六个基本动作数据采集过程与之类似。记录完成后，需要每张图片所对应的指令标签做手动调整，这是由于（）中每个指令元素对于某一基本动作贡献不同，如左右平移运动时，起支配作用的指令为h；上下运动时，支配指令为h，为避免模糊指令，手动调整原则为尽量增加起支配作用的指令元素值，于此同时弱化其他指令元素，图2-9展示了向右运动时数据采集及处理过程。
\[图2-9]






